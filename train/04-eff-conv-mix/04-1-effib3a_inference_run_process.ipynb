{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, cv2, math, copy, time, random\n",
    "import pickle\n",
    "# For data manipulation\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils.utils_2dcnn import *\n",
    "from utils.model_2dcnn import Net, criterion\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028 704\n"
     ]
    }
   ],
   "source": [
    "types_ = 'challenge'\n",
    "# types_ = 'non_challenge'\n",
    "# Get data dict\n",
    "if types_=='challenge':\n",
    "    with open('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_train_dic1_05_challenge.pickle', 'rb') as f: #train dict challenge\n",
    "        train_dic = pickle.load(f)\n",
    "    with open('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_valid_dic1_05_challenge.pickle', 'rb') as f: #valid dict challenge\n",
    "        valid_dlc = pickle.load(f)\n",
    "    train_df = pd.read_csv('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_train_df_challenge.csv') #train df challenge\n",
    "    valid_df = pd.read_csv('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_valid_df_challenge.csv') #valid df challenge\n",
    "else:\n",
    "    with open('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_train_dic1_05.pickle', 'rb') as f: #train dict non-challenge\n",
    "        train_dic = pickle.load(f)\n",
    "    with open('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_valid_dic1_05.pickle', 'rb') as f: #valid dict non-challenge\n",
    "        valid_dlc = pickle.load(f)\n",
    "    train_df = pd.read_csv('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_train_df.csv') #train df non-challenge\n",
    "    valid_df = pd.read_csv('/ssd8/2023COVID19/Train_Valid_dataset/filter_slice_valid_df.csv') #valid df non-challenge\n",
    "print(len(train_dic), len(valid_dlc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== loading *model* ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4\"\n",
    "set_seed()\n",
    "job=51  \n",
    "CONFIG = {\"seed\": 2022,\n",
    "        \"img_size\": 384, #image size: 512\n",
    "        \"train_batch_size\": 8, #16\n",
    "        \"valid_batch_size\": 16,\n",
    "        \"n_accumulate\": 1, #2\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        \"train_batch\":16,\n",
    "            }\n",
    "\n",
    "data_transforms = {\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()], p=1.)\n",
    "}\n",
    "\n",
    "\n",
    "print(\"=\"*10, \"loading *model*\", \"=\"*10)\n",
    "model=Net()\n",
    "# model = nn.DataParallel(model, device_ids=[0,1])\n",
    "model=model.to(CONFIG['device'])\n",
    "# pred_path='/home/chihyi111/covid_2023/train_code_challenge/model/loss/job_51_effnetb3a_size256_challenge[DataParallel].bin'#weight path\n",
    "pred_path = \"/ssd8/2023COVID19/CT-COVID19-Classification/train_code_fix/model/f1/job_51_effnetb3a_size384_challenge[DataParallel]_146.bin\"\n",
    "# pred_path ='/ssd8/2023COVID19/CT-COVID19-Classification/train_code_fix/model/f1/job_51_effnetb3a_size384_challenge[DataParallel].bin'#weight path\n",
    "# pred_path='/ssd8/2023COVID19/CT-COVID19-Classification/train_code_fix/model/f1/job_51_effnetb3a_size256_challenge[DataParallel].bin'#weight path\n",
    "ck_point = torch.load(pred_path)\n",
    "model.load_state_dict(ck_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:44<00:00,  1.02s/it]\n",
      "100%|██████████| 44/44 [00:48<00:00,  1.10s/it]\n",
      "100%|██████████| 44/44 [00:55<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8645790537347389\n",
      "0.8627288724021497\n",
      "0.8672291095211835\n",
      "Mean F1-Score: 0.863084395871281\n",
      "Negative Accuracy: 0.9530916844349681\n",
      "Positive Accuracy: 0.7446808510638298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def pred_one(model, dataloader, device):\n",
    "    model.eval()\n",
    "    true_y=[]\n",
    "    pred_y=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            ct_b, img_b, c, h, w = data['image'].size()\n",
    "            data_img = data['image'].reshape(-1, c, h, w)\n",
    "            data_label = data['label'].reshape(-1,1)\n",
    "            images = data_img.to(device, dtype=torch.float)\n",
    "            labels = data_label.to(device, dtype=torch.float)\n",
    "            outputs = model(images)\n",
    "            true_y.append(labels.cpu().numpy())\n",
    "            pred_y.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "    true_y=np.concatenate(true_y)\n",
    "    pred_y=np.concatenate(pred_y)\n",
    "    gc.collect()\n",
    "    # print(pred_y.shape)\n",
    "    true_y=np.array(true_y).reshape(-1,1)\n",
    "    true_y=np.array(true_y).reshape(-1,img_b)\n",
    "    true_y=true_y.mean(axis=1)\n",
    "    pred_y=np.array(pred_y).reshape(-1,1)\n",
    "    # print(pred_y.shape)\n",
    "    pred_y=np.array(pred_y).reshape(-1,img_b)\n",
    "    # print(pred_y.shape)\n",
    "    pred_y=pred_y.mean(axis=1)\n",
    "    # print(pred_y.shape)\n",
    "    return true_y,pred_y\n",
    "\n",
    "total_pred=[]\n",
    "train_loader, valid_loader = prepare_loaders_eval(CONFIG, train_df, train_dic, valid_df, valid_dlc, data_transforms)\n",
    "for i in range(3):\n",
    "    true_y,pred_y=pred_one(model, valid_loader, device=CONFIG['device'])\n",
    "    total_pred.append(pred_y)\n",
    "for i in range(len(total_pred)):\n",
    "    print(f1_score(np.array(true_y),np.round(total_pred[i]),average='macro'))   \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(np.array(true_y), np.round(np.mean(total_pred,axis=0))).ravel()\n",
    "print(\"Mean F1-Score: {}\".format(f1_score(np.array(true_y),np.round(np.mean(total_pred,axis=0)),average='macro')))\n",
    "print(\"Negative Accuracy: {}\".format(tn/(tn+fp)))#Specificity\n",
    "print(\"Positive Accuracy: {}\".format(tp/(tp+fn)))#Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============[baseline]==============\n",
    "# model: 2dcnn(efficientnet_b3a)\n",
    "# LR: (0.0001, decay:0.0005)\n",
    "# batch size: 8\n",
    "# ------------------------------------\n",
    "# non-challenge dataset:\n",
    "# [256x256] [DataParallel] (weight =  best f1 socre checkpoint)\n",
    "# Mean F1-Score: 0.9200561009817672\n",
    "# Negative Accuracy: 0.9774436090225563\n",
    "# Positive Accuracy: 0.8545454545454545\n",
    "\n",
    "# [384x384] [DataParallel] (weight =  best f1 socre checkpoint\n",
    "# Mean F1-Score: 0.9305508039685255\n",
    "# Negative Accuracy: 0.9721030042918455\n",
    "# Positive Accuracy: 0.8739130434782608\n",
    "# ------------------------------------\n",
    "# challenge dataset:\n",
    "# [256x256] [DataParallel] (weight =  best f1 socre checkpoint)\n",
    "# Mean F1-Score: 0.8918847674637544\n",
    "# Negative Accuracy: 0.9377682403433476\n",
    "# Positive Accuracy: 0.8391304347826087\n",
    "\n",
    "# [384x384] [DataParallel] (weight =  best f1 socre checkpoint\n",
    "# Mean F1-Score: 0.9271816605663649\n",
    "# Negative Accuracy: 0.943609022556391\n",
    "# Positive Accuracy: 0.9090909090909091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59460f4696914c2b63c32a491cda090056eb06068fec4b5dfed046fe694fcf36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
