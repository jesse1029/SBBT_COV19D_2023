{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, numpy as np, random,gc\n",
    "import copy, cv2\n",
    "pd.options.mode.chained_assignment = None\n",
    "import torch, torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_01 = pd.read_csv('./csv_pickle/df_224_sz384_0.csv')\n",
    "# df_test_02 = pd.read_csv('./csv_pickle/df_224_sz384_1.csv')\n",
    "# df_test_03 = pd.read_csv('./csv_pickle/df_224_sz384_2.csv')\n",
    "# df_test_04 = pd.read_csv('./csv_pickle/df_224_sz384_3.csv')\n",
    "# df = pd.concat([df_test_01,df_test_02,df_test_03,df_test_04])\n",
    "# df.to_csv('./csv_pickle/df_224_embed_sz_384_146server.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fix path\n",
    "# df_224_3d = pd.read_csv(\"./csv_pickle/df_224_embed.csv\")\n",
    "# ct_path_stack = []\n",
    "# for old_path in df_224_3d['ct_path'].tolist():\n",
    "#     old_ = '/ssd2/COVID2023_data_embed_npy/'\n",
    "#     new_ = '/ssd8/2023COVID19/2023_covid/COVID2023_data_embed_npy/'\n",
    "#     new_path = old_path.replace(old_, new_)\n",
    "#     ct_path_stack.append(new_path)\n",
    "# df_224_3d['ct_path'] = ct_path_stack\n",
    "# df_224_3d.to_csv(\"./csv_pickle/df_224_embed_146server.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改init讀取全部embed的方法（記憶體無法負擔所有npy資料），改以呼叫index階段時再進行讀取\n",
    "class COVID_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, data_split, ct_len_s=50 , transform = None):\n",
    "        if data_split == 'test':\n",
    "            dataset = pd.read_pickle(csv_path)\n",
    "            self.embed_info = dataset\n",
    "            classes = [999]\n",
    "            classes = sorted(list(classes))\n",
    "            class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "            ct_path = np.unique(dataset.iloc[:, 2])\n",
    "            imgs = []\n",
    "            for i_scan_dir in tqdm(ct_path):\n",
    "                temp_df = dataset[dataset['ct_path'] == i_scan_dir]\n",
    "                imgs.append((i_scan_dir, 999))\n",
    "            \n",
    "        elif data_split == 'train' or 'valid': \n",
    "            df = pd.read_csv(csv_path)\n",
    "            # df['embed'] = self.load_npy(df.ct_path.values.tolist(), df.embed.values.tolist())\n",
    "            dataset = df[df['split'] == data_split]\n",
    "            self.embed_info = dataset\n",
    "            \n",
    "            classes = set(dataset['label'])\n",
    "            classes = sorted(list(classes))\n",
    "            class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "            \n",
    "            ct_path = np.unique(dataset.iloc[:, 4])\n",
    "            imgs = []\n",
    "            for i_scan_dir in tqdm(ct_path):\n",
    "                temp_df = dataset[dataset['ct_path'] == i_scan_dir]\n",
    "                imgs.append((i_scan_dir, temp_df.iloc[0, 3]))\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.ct_len_s = ct_len_s\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "    def load_npy(self, npy_path, npy_file):\n",
    "        new_npy_embed = []\n",
    "        for path_, file_ in zip(npy_path, npy_file):\n",
    "            new_npy_embed.append(np.load(os.path.join(path_, file_)))\n",
    "        return new_npy_embed\n",
    "    def __getitem__(self, index):\n",
    "        img_scan_dir, label = self.imgs[index]\n",
    "        \n",
    "        label = self.class_to_idx[label]\n",
    "        temp_df = self.embed_info[self.embed_info['ct_path'] == img_scan_dir]\n",
    "        temp_df['embed'] = self.load_npy(temp_df['ct_path'].values.tolist(), temp_df['embed'].values.tolist())\n",
    "        random.seed(4019)\n",
    "        if len(temp_df) >= self.ct_len_s:\n",
    "            temp_index = [x for x in range(len(temp_df))]\n",
    "            target_index = random.sample(temp_index, k = self.ct_len_s)\n",
    "            \n",
    "        elif len(temp_df) < self.ct_len_s:\n",
    "            target_index = [x for x in range(len(temp_df))]\n",
    "            temp = random.choices(target_index, k = self.ct_len_s - len(target_index))\n",
    "            target_index += temp\n",
    "        \n",
    "        target_index.sort()\n",
    "        embed = temp_df.iloc[target_index, 1]\n",
    "        img = []\n",
    "        for i_embed in embed:\n",
    "            img.append(i_embed)\n",
    "        # img = np.expand_dims(np.array(img).reshape((1536, 8*8*self.ct_len_s)), axis=0)\n",
    "        img = np.array(img)\n",
    "        if len(img.shape)==4:\n",
    "            img = np.array(img).reshape((1536, 8*8*self.ct_len_s))\n",
    "        # else:\n",
    "        #     img = img.reshape((img.shape[1],img.shape[0]))\n",
    "        # img = np.concatenate([img,img,img], axis=0)\n",
    "        # print(img.shape)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, ct_len=224, kernal_size = 3, pre_train=True):\n",
    "        super(MyModel, self).__init__()\n",
    "        # self.conv1d = nn.Conv1d(in_channels=224, out_channels=CONFIG.ct_len_get, kernel_size=kernal_size)\n",
    "        self.conv1d = nn.Conv1d(in_channels=100, out_channels=CONFIG.ct_len_get, kernel_size=kernal_size)\n",
    "        self.backbone = timm.create_model('resnet18', pretrained=pre_train, num_classes=1)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1d(x)\n",
    "        \n",
    "        x = torch.cat((x.unsqueeze(1), x.unsqueeze(1), x.unsqueeze(1)), dim=1)\n",
    "        \n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # model_path1 = \"/ssd8/2023COVID19/CT-COVID19-Classification/train_code_fix/output/f1_best_model_k1_convembed_check_from144weight[384].bin\"\n",
    "    model_path1 = \"/ssd8/2023COVID19/CT-COVID19-Classification/train_code_fix/output/f1_best_model_k1_convslice_check_from144weight[384].bin\"\n",
    "    pre_train = False\n",
    "    N_EPOCHS = 100\n",
    "    train_batch_size = 32\n",
    "    valid_batch_size = 32\n",
    "    ct_len_get = 100 #100\n",
    "    kernal_size = 1 #1\n",
    "    SEDD =42\n",
    "    LR = 3e-5 #3e-5\n",
    "    WEIGHT_DECAY = 1e-3 #1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean 10\n",
    "def valid_one(model, loader):\n",
    "    losses, predicts = [], []\n",
    "    true_y=[]\n",
    "    pred_y=[]\n",
    "    model.eval()\n",
    "    for images, label in loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.cuda().float()\n",
    "            labels = label.cuda().float()\n",
    "            out = model(images)\n",
    "        predicts.append(out.cpu())\n",
    "        true_y.append(labels.cpu().numpy())\n",
    "        pred_y.append(torch.sigmoid(out).cpu().numpy())\n",
    "        \n",
    "    true_y=np.concatenate(true_y)\n",
    "    pred_y=np.concatenate(pred_y)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    true_y=np.array(true_y).reshape(-1,1)\n",
    "    pred_y=np.array(pred_y).reshape(-1,1)\n",
    "\n",
    "    return true_y,pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========data loader==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [00:06<00:00, 105.00it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_path = CONFIG.model_path1\n",
    "model = MyModel(ct_len = CONFIG.ct_len_get, kernal_size=CONFIG.kernal_size, pre_train=CONFIG.pre_train).cuda()\n",
    "model.load_state_dict(torch.load(pred_path))\n",
    "model.cuda()\n",
    "# df_path = './csv_pickle/df_224_embed_146server.csv' #144 server embedding result path\n",
    "df_path = './csv_pickle/df_224_embed_sz_384_146server.csv'\n",
    "print(\"==========data loader==========\")\n",
    "valid_ds = COVID_Dataset(csv_path = df_path,data_split = 'valid', ct_len_s = CONFIG.ct_len_get, transform = None)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=CONFIG.valid_batch_size, num_workers=15, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-Score: 0.8884825444051875\n",
      "Negative Accuracy: 0.9381663113006397\n",
      "Positive Accuracy: 0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "total_pred=[]\n",
    "for i in range(10):\n",
    "    true_y,pred_y=valid_one(model, valid_loader)\n",
    "    total_pred.append(pred_y)\n",
    "# for i in range(len(total_pred)):\n",
    "#     print(f1_score(np.array(true_y),np.round(total_pred[i]),average='macro'))  \n",
    "tn, fp, fn, tp = confusion_matrix(np.array(true_y), np.round(np.mean(total_pred,axis=0))).ravel()\n",
    "print(\"Mean F1-Score: {}\".format(f1_score(np.array(true_y),np.round(np.mean(total_pred,axis=0)),average='macro')))\n",
    "print(\"Negative Accuracy: {}\".format(tn/(tn+fp)))\n",
    "print(\"Positive Accuracy: {}\".format(tp/(tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# model: 2dcnn(efficientnet_b3a) + 1dcnn + resnet18 (from 144 server)\n",
    "# LR: (0.0001, decay:0.0005)\n",
    "# batch size: 8\n",
    "# image size: [384x384]\n",
    "# datatype: challenge data\n",
    "# (weight =  best f1 socre checkpoint)\n",
    "# ------------------------------------\n",
    "# 以embedding dim做1d conv\n",
    "# Mean F1-Score: 0.8830530189078547\n",
    "# Negative Accuracy: 0.9253731343283582\n",
    "# Positive Accuracy: 0.8382978723404255\n",
    "# ------------------------------------\n",
    "# 以slice dim做1d conv\n",
    "# Mean F1-Score: 0.8884825444051875\n",
    "# Negative Accuracy: 0.9381663113006397\n",
    "# Positive Accuracy: 0.8297872340425532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed result*\n",
    "# ======================================\n",
    "# model: 2dcnn(efficientnet_b3a) + 1dcnn + resnet18\n",
    "# LR: (0.0001, decay:0.0005)\n",
    "# batch size: 8\n",
    "# image size: [256x256]\n",
    "# datatype: challenge data\n",
    "# (weight =  best f1 socre checkpoint)\n",
    "# ------------------------------------\n",
    "# 以embedding dim做1d conv\n",
    "# Mean F1-Score: 0.9221583370190181\n",
    "# Specificity: 0.9637526652452025\n",
    "# Sensitivity: 0.8680851063829788\n",
    "# ------------------------------------\n",
    "# 以slice dim做1d conv\n",
    "# Mean F1-Score: 0.913347004465955\n",
    "# Specificity: 0.9658848614072495\n",
    "# Sensitivity: 0.8425531914893617\n",
    "\n",
    "# 路徑：/ssd8/2023COVID19/CT-COVID19-Classification/train_code_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# model: 2dcnn(efficientnet_b3a) + 1dcnn + resnet18\n",
    "# LR: (0.0001, decay:0.0005)\n",
    "# batch size: 8\n",
    "# image size: [384x384]\n",
    "# datatype: challenge data\n",
    "# (weight =  best f1 socre checkpoint)\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=1; ct_len=100[pretrain=True]\n",
    "# Mean F1-Score: 0.8964\n",
    "# Negative Accuracy: 0.9744\n",
    "# Positive Accuracy: 0.7872\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=3; ct_len=100[pretrain=True]\n",
    "# Mean F1-Score: 0.8964\n",
    "# Negative Accuracy: 0.9744\n",
    "# Positive Accuracy: 0.7872\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=1; ct_len=100[pretrain=False]\n",
    "# Mean F1-Score: 0.9221\n",
    "# Negative Accuracy: 0.9637\n",
    "# Positive Accuracy: 0.8680\n",
    "# ------------------------------------\n",
    "# [conv axis=slice]\n",
    "# kernel=1; ct_len=100[pretrain=False]\n",
    "# Mean F1-Score: 0.9133\n",
    "# Negative Accuracy: 0.9658\n",
    "# Positive Accuracy: 0.0.8425\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=3; ct_len=100[pretrain=False]\n",
    "# Mean F1-Score: 0.9160\n",
    "# Negative Accuracy: 0.9744\n",
    "# Positive Accuracy: 0.8340\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=7; ct_len=100[pretrain=False]\n",
    "# Mean F1-Score: 0.9150\n",
    "# Negative Accuracy: 0.9658\n",
    "# Positive Accuracy: 0.8468\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=1; ct_len=200[pretrain=False]\n",
    "# Mean F1-Score: 0.9076\n",
    "# Negative Accuracy: 0.9701\n",
    "# Positive Accuracy: 0.8212\n",
    "# ------------------------------------\n",
    "# [conv axis=embedding]\n",
    "# kernel=1; ct_len=224[pretrain=False]\n",
    "# Mean F1-Score: 0.9015\n",
    "# Negative Accuracy: 0.9616\n",
    "# Positive Accuracy: 0.8212"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e4eaf7fc1241741242c84999f2000af8b451353219079a4e5df2fc9b8f3715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
